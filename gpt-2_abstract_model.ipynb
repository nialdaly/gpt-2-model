{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpt_2_simple as gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = gpt2.start_tf_sess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/nialdaly/Documents/gpt-2_model/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading checkpoint checkpoint/run1/model-3000\n",
      "WARNING:tensorflow:From /Users/nialdaly/Documents/gpt-2_model/venv/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-3000\n"
     ]
    }
   ],
   "source": [
    "gpt2.load_gpt2(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(start_sentence):\n",
    "    # start_sentence = \"Most state-of-the-art text detection methods are specific to horizontal Latin text and are not fast enough for real-time applications. We introduce Segment Linking (SegLink), an oriented text detection method.\"\n",
    "    #\n",
    "    single_text = gpt2.generate(sess,\n",
    "        length = 200,\n",
    "        temperature = 0.7,\n",
    "        prefix = start_sentence,\n",
    "        nsamples = 5,\n",
    "        batch_size = 5,\n",
    "        return_as_list=True\n",
    "        )[0]\n",
    "\n",
    "    return single_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start_sentence = \"comma.ai’s approach to Artificial Intelligence for self-driving cars\"\n",
    "# start_sentence = \"comma.ai’s approach to Artificial Intelligence for self-driving cars\"\n",
    "\n",
    "# # single_text = gpt2.generate(sess, return_as_list=True)[0]\n",
    "# print(model_output(start_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "start_sentence = \"Self-driving cars are one of the most promising prospects for near term Artificial Intelligence research.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "result = model_output(start_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-driving cars are one of the most promising prospects for near term Artificial Intelligence research. However, until now, deep neural networks wereCC-instructed via standard image-based models. Particularly, Capsized CNNs (CvSci) exhibit significant improvement over DCCNNs in capturing high-level semantic features. However, the size of these CNNs has graduallyincreasingly becomeincreasingly difficult to train. Also, artificial neural networks are not compatible with them, which makes these networks veryspecialized. In this paper, we introduce a new gradient-based method to learnconvolutional neural networks (CNNs) with a single fully convolutional network, which useslow-resolution images to encode the presentation feature. We firstdistributes the convolution filterspools to the convolutional network, which thenmaps the features in the full convolutional network to the low-resolution images. This method is simpler and lessrelatively expensive than standard neuralCNN. Whileavailability of trained CNNs is an important factor that contributes to its success,it remains an open\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "create a formulaic abstract from data\n",
    "\n",
    "create a fill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-2-model",
   "language": "python",
   "name": "gpt-2-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

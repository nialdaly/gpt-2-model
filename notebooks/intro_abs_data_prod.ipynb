{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>Abstract:  Most state-of-the-art text detectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>Abstract:  We present a memory augmented neura...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>Abstract:  This document describes Pythia v0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Scale GAN Training for High Fidelity Nat...</td>\n",
       "      <td>Abstract:  Despite recent progress in generati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Margin-based Parallel Corpus Mining with Multi...</td>\n",
       "      <td>Abstract:  Machine translation is highly sensi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "3  Large Scale GAN Training for High Fidelity Nat...   \n",
       "4  Margin-based Parallel Corpus Mining with Multi...   \n",
       "\n",
       "                                            abstract  \n",
       "0  Abstract:  Most state-of-the-art text detectio...  \n",
       "1  Abstract:  We present a memory augmented neura...  \n",
       "2  Abstract:  This document describes Pythia v0.1...  \n",
       "3  Abstract:  Despite recent progress in generati...  \n",
       "4  Abstract:  Machine translation is highly sensi...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100 = pd.read_csv('../data/gpt-2_data_100.csv')\n",
    "df_200 = pd.read_csv('../data/gpt-2_data_200.csv')\n",
    "df_300 = pd.read_csv('../data/gpt-2_data_300.csv')\n",
    "\n",
    "abs_df = pd.concat([df_100, df_200], sort=True)\n",
    "abs_df = pd.concat([abs_df, df_300], sort=True)\n",
    "\n",
    "abs_df = abs_df[['paper_title', 'abstract']]\n",
    "\n",
    "abs_df = abs_df.reset_index(drop=True)\n",
    "\n",
    "abs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# intros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>introduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>Reading text in natural images is a challengin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>Recurrent neural networks (RNNs) have been suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>We present Pythia v0.1, a modular framework fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Scale GAN Training for High Fidelity Nat...</td>\n",
       "      <td>The state of generative image modeling has adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Margin-based Parallel Corpus Mining with Multi...</td>\n",
       "      <td>Given the prevalence of corpus-based approache...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "3  Large Scale GAN Training for High Fidelity Nat...   \n",
       "4  Margin-based Parallel Corpus Mining with Multi...   \n",
       "\n",
       "                                        introduction  \n",
       "0  Reading text in natural images is a challengin...  \n",
       "1  Recurrent neural networks (RNNs) have been suc...  \n",
       "2  We present Pythia v0.1, a modular framework fo...  \n",
       "3  The state of generative image modeling has adv...  \n",
       "4  Given the prevalence of corpus-based approache...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_df = pd.read_excel('../data/paper_metadata.xlsx')\n",
    "\n",
    "intro_df = intro_df[['paper_title', 'introduction']]\n",
    "\n",
    "intro_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join abstracts & intros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>introduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>Abstract:  Most state-of-the-art text detectio...</td>\n",
       "      <td>Reading text in natural images is a challengin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>Abstract:  We present a memory augmented neura...</td>\n",
       "      <td>Recurrent neural networks (RNNs) have been suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>Abstract:  This document describes Pythia v0.1...</td>\n",
       "      <td>We present Pythia v0.1, a modular framework fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Margin-based Parallel Corpus Mining with Multi...</td>\n",
       "      <td>Abstract:  Machine translation is highly sensi...</td>\n",
       "      <td>Given the prevalence of corpus-based approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Probabilistic Model-Agnostic Meta-Learning</td>\n",
       "      <td>Abstract:  Meta-learning for few-shot learning...</td>\n",
       "      <td>Learning from a few examples is a key aspect o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "3  Margin-based Parallel Corpus Mining with Multi...   \n",
       "4         Probabilistic Model-Agnostic Meta-Learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract:  Most state-of-the-art text detectio...   \n",
       "1  Abstract:  We present a memory augmented neura...   \n",
       "2  Abstract:  This document describes Pythia v0.1...   \n",
       "3  Abstract:  Machine translation is highly sensi...   \n",
       "4  Abstract:  Meta-learning for few-shot learning...   \n",
       "\n",
       "                                        introduction  \n",
       "0  Reading text in natural images is a challengin...  \n",
       "1  Recurrent neural networks (RNNs) have been suc...  \n",
       "2  We present Pythia v0.1, a modular framework fo...  \n",
       "3  Given the prevalence of corpus-based approache...  \n",
       "4  Learning from a few examples is a key aspect o...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_abs = pd.merge(abs_df, intro_df, on='paper_title')\n",
    "\n",
    "intro_abs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>introduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>Most state-of-the-art text detection methods a...</td>\n",
       "      <td>Reading text in natural images is a challengin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>We present a memory augmented neural network f...</td>\n",
       "      <td>Recurrent neural networks (RNNs) have been suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>This document describes Pythia v0.1, the winni...</td>\n",
       "      <td>We present Pythia v0.1, a modular framework fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Margin-based Parallel Corpus Mining with Multi...</td>\n",
       "      <td>Machine translation is highly sensitive to the...</td>\n",
       "      <td>Given the prevalence of corpus-based approache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Probabilistic Model-Agnostic Meta-Learning</td>\n",
       "      <td>Meta-learning for few-shot learning entails ac...</td>\n",
       "      <td>Learning from a few examples is a key aspect o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "3  Margin-based Parallel Corpus Mining with Multi...   \n",
       "4         Probabilistic Model-Agnostic Meta-Learning   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Most state-of-the-art text detection methods a...   \n",
       "1  We present a memory augmented neural network f...   \n",
       "2  This document describes Pythia v0.1, the winni...   \n",
       "3  Machine translation is highly sensitive to the...   \n",
       "4  Meta-learning for few-shot learning entails ac...   \n",
       "\n",
       "                                        introduction  \n",
       "0  Reading text in natural images is a challengin...  \n",
       "1  Recurrent neural networks (RNNs) have been suc...  \n",
       "2  We present Pythia v0.1, a modular framework fo...  \n",
       "3  Given the prevalence of corpus-based approache...  \n",
       "4  Learning from a few examples is a key aspect o...  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removes the abstract header from each string in the abstract column\n",
    "intro_abs['abstract'] = intro_abs['abstract'].map(lambda x: str(x)[11:])\n",
    "\n",
    "# removes unnecessary new lines\n",
    "intro_abs['abstract'] = intro_abs['abstract'].replace(r'\\n',' ', regex=True)\n",
    "\n",
    "intro_abs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Most state-of-the-art text detection methods are specific to horizontal Latin text and are not fast enough for real-time applications. We introduce Segment Linking (SegLink), an oriented text detection method. The main idea is to decompose text into two locally detectable elements, namely segments and links. A segment is an oriented box covering a part of a word or text line; A link connects two adjacent segments, indicating that they belong to the same word or text line. Both elements are detected densely at multiple scales by an end-to-end trained, fully-convolutional neural network. Final detections are produced by combining segments connected by links. Compared with previous methods, SegLink improves along the dimensions of accuracy, speed, and ease of training. It achieves an f-measure of 75.0% on the standard ICDAR 2015 Incidental (Challenge 4) benchmark, outperforming the previous best by a large margin. It runs at over 20 FPS on 512x512 images. Moreover, without modification, SegLink is able to detect long lines of non-Latin text, such as Chinese. '"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = intro_abs.iloc[0][1]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_abs.to_csv('../data/intro_abs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_abs_list = []\n",
    "\n",
    "for index, row in intro_abs.iterrows():    \n",
    "    intro_abs_list.append(row['introduction'] + \"\\n\\n\" + row['abstract'] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reading text in natural images is a challenging task under active research. It is driven by many real-world applications, such as Photo OCR [2], geo-location, and image retrieval [9]. In a text reading system, text detection, i.e. localizing text with bounding boxes of words or text lines, is usually the first step of great significance. In a sense, text detection can be seen as object detection applied to text, where words/characters/text lines are taken as the detection targets. Owing to this, a new trend has emerged recently that state-of-the-art text detection methods [9, 6, 22, 30] are heavily based on the advanced general object detection or segmentation techniques, e.g. [4, 5, 15]. Despite the great success of the previous work, we argue that the general detection methods are not well suited for text detection, for two main reasons. First, word/text line bounding boxes have much larger aspect ratios than those of general objects. An (fast/faster) R-CNN [5, 4, 19]- or SSD [14]-style detector may suffer from the difficulty of producing such boxes, owing to its proposal or anchor box design. In addition, some non-Latin text does not have blank spaces between words, hence the even larger bounding box aspect ratios, which make the problem worse. Second, unlike general objects, text usually has a clear definition of orientation [25]. It is important for a text detector to produce oriented boxes. However, most general object detection methods are not designed to produce oriented boxes. To overcome the above challenges, we tackle the text detection problem in a new perspective. We propose to decompose long text into two smaller and locally-detectable elements, namely segment and link. As illustrated in Fig. 1, a segment is an oriented box that covers a part of a word (for clarity we use “word” here and later on, but segments also work seamlessly on text lines that comprise multiple words); A link connects a pair of adjacent segments, indicating that they belong to the same word. Under the above definitions, a word is located by a number of segments with links between them. During detection, segments and links are densely detected on an input image by a convolutional neural network. Then, the segments are combined into whole words according to the links. The key advantage of this approach is that long and oriented text is now detected locally since both basic elements are locally-detectable: Detecting a segment does not require the whole word to be observed. And neither does a link since the connection of two segments can be inferred from a local context. Thereafter, we can detect text of any length and orientation with great flexibility and efficiency. Concretely, we propose a convolutional neural network (CNN) model to detect both segments and links simultaneously, in a fully-convolutional manner. The network uses VGG-16 [21] as its backbone. A few extra feature layers are added onto it. Convolutional predictors are added to 6 of the feature layers to detect segments and links at different scales. To deal with redundant detections, we introduce two types of links, namely within-layer links and cross-layer links. A within-layer link connects a segment to its neighbors on the same layer. A cross-layer link, on the other hand, connects a segment to its neighbors on the lower layer. In this way, we connect segments of adjacent locations as well as scales. Finally, we find connected segments with a depth-first search (DFS) algorithm and combine them into whole words. Our main contribution is the novel segment-linking detection method. Through experiments, we show that the proposed method possesses several distinctive advantages over the other state-of-the-art methods: 1) Robustness: SegLink models the structure of oriented text in a simple and elegant way, with robustness against complex backgrounds. Our method achieves highly competitive results on standard datasets. In particular, it outperforms the previous best by a large margin in terms of f-measure (75.0% vs 64.8%) on the ICDAR 2015 Incidental (Challenge 4) benchmark [12]; 2) Efficiency: SegLink is highly efficient due to its single-pass, fully-convolutional design. It processes more than 20 images of 512x512 size per second; 3) Generality: Without modification, SegLink is able to detect long lines of non-Latin text, such as Chinese. We demonstrate this capability on a multi-lingual dataset.\\n\\nMost state-of-the-art text detection methods are specific to horizontal Latin text and are not fast enough for real-time applications. We introduce Segment Linking (SegLink), an oriented text detection method. The main idea is to decompose text into two locally detectable elements, namely segments and links. A segment is an oriented box covering a part of a word or text line; A link connects two adjacent segments, indicating that they belong to the same word or text line. Both elements are detected densely at multiple scales by an end-to-end trained, fully-convolutional neural network. Final detections are produced by combining segments connected by links. Compared with previous methods, SegLink improves along the dimensions of accuracy, speed, and ease of training. It achieves an f-measure of 75.0% on the standard ICDAR 2015 Incidental (Challenge 4) benchmark, outperforming the previous best by a large margin. It runs at over 20 FPS on 512x512 images. Moreover, without modification, SegLink is able to detect long lines of non-Latin text, such as Chinese. \\n\\n']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_abs_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/intro_abs_data.txt', 'w') as myfile:  \n",
    "    myfile.write('\\n\\n'.join(str(line) for line in intro_abs_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-2-model",
   "language": "python",
   "name": "gpt-2-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

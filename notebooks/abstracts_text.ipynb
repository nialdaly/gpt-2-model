{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>introduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>Reading text in natural images is a challengin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>Recurrent neural networks (RNNs) have been suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>We present Pythia v0.1, a modular framework fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "\n",
       "                                        introduction  \n",
       "0  Reading text in natural images is a challengin...  \n",
       "1  Recurrent neural networks (RNNs) have been suc...  \n",
       "2  We present Pythia v0.1, a modular framework fo...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.read_excel('../data/paper_metadata.xlsx', index_col=False)\n",
    "metadata = metadata[['paper_title', 'introduction']]\n",
    "\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>The metric used to validate the model was F-me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>The metric used to validate the model was % Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>The metric used to validate the model was Accu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "\n",
       "                                                 abs  \n",
       "0  The metric used to validate the model was F-me...  \n",
       "1  The metric used to validate the model was % Te...  \n",
       "2  The metric used to validate the model was Accu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_df = pd.read_csv('../data/metadata_abstracts.csv')\n",
    "\n",
    "abstracts_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataframe joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>abs</th>\n",
       "      <th>introduction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>The metric used to validate the model was F-me...</td>\n",
       "      <td>Reading text in natural images is a challengin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>The metric used to validate the model was % Te...</td>\n",
       "      <td>Recurrent neural networks (RNNs) have been suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>The metric used to validate the model was Accu...</td>\n",
       "      <td>We present Pythia v0.1, a modular framework fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Scale GAN Training for High Fidelity Nat...</td>\n",
       "      <td>The metric used to validate the model was FID ...</td>\n",
       "      <td>The state of generative image modeling has adv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Margin-based Parallel Corpus Mining with Multi...</td>\n",
       "      <td>The metric used to validate the model was F1 s...</td>\n",
       "      <td>Given the prevalence of corpus-based approache...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "1                           Neural Semantic Encoders   \n",
       "2  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "3  Large Scale GAN Training for High Fidelity Nat...   \n",
       "4  Margin-based Parallel Corpus Mining with Multi...   \n",
       "\n",
       "                                                 abs  \\\n",
       "0  The metric used to validate the model was F-me...   \n",
       "1  The metric used to validate the model was % Te...   \n",
       "2  The metric used to validate the model was Accu...   \n",
       "3  The metric used to validate the model was FID ...   \n",
       "4  The metric used to validate the model was F1 s...   \n",
       "\n",
       "                                        introduction  \n",
       "0  Reading text in natural images is a challengin...  \n",
       "1  Recurrent neural networks (RNNs) have been suc...  \n",
       "2  We present Pythia v0.1, a modular framework fo...  \n",
       "3  The state of generative image modeling has adv...  \n",
       "4  Given the prevalence of corpus-based approache...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstracts_df = pd.merge(abstracts_df, metadata, on='paper_title')\n",
    "\n",
    "abstracts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text file generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/new_sentence.')\n",
    "\n",
    "\n",
    "for i in range(len(arr)):\n",
    "    \n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-2-model",
   "language": "python",
   "name": "gpt-2-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

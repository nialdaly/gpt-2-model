{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from html.parser import HTMLParser\n",
    "import pandas as pd\n",
    "import re\n",
    "import tika\n",
    "from tika import parser\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>extradata</th>\n",
       "      <th>global_rank</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>model</th>\n",
       "      <th>remove</th>\n",
       "      <th>task</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_path</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC15</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 10</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Scene Text Detection</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  extradata global_rank metric_name metric_value    model remove  \\\n",
       "0    IC15        NaN        # 10   F-Measure       75.61%  SegLink      -   \n",
       "\n",
       "                   task                                        paper_title  \\\n",
       "0  Scene Text Detection  Detecting Oriented Text in Natural Images by L...   \n",
       "\n",
       "                                          paper_path  \\\n",
       "0  /paper/detecting-oriented-text-in-natural-imag...   \n",
       "\n",
       "                                paper_url  \n",
       "0  https://arxiv.org/pdf/1703.06520v3.pdf  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/pw_code_model_data.csv', encoding='latin-1')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>extradata</th>\n",
       "      <th>global_rank</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>model</th>\n",
       "      <th>remove</th>\n",
       "      <th>task</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_path</th>\n",
       "      <th>paper_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC15</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 10</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Scene Text Detection</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  extradata global_rank metric_name metric_value    model remove  \\\n",
       "0    IC15        NaN        # 10   F-Measure       75.61%  SegLink      -   \n",
       "\n",
       "                   task                                        paper_title  \\\n",
       "0  Scene Text Detection  Detecting Oriented Text in Natural Images by L...   \n",
       "\n",
       "                                          paper_path  \\\n",
       "0  /paper/detecting-oriented-text-in-natural-imag...   \n",
       "\n",
       "                                paper_url  \n",
       "0  https://arxiv.org/pdf/1703.06520v3.pdf  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate papers\n",
    "df = df.drop_duplicates(subset='paper_url')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1165"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "df = df[df['paper_url'].str.contains(\"arxiv\")]\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>extradata</th>\n",
       "      <th>global_rank</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>model</th>\n",
       "      <th>remove</th>\n",
       "      <th>task</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_path</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC15</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 10</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Scene Text Detection</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1703.06520v3.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  extradata global_rank metric_name metric_value    model remove  \\\n",
       "0    IC15        NaN        # 10   F-Measure       75.61%  SegLink      -   \n",
       "\n",
       "                   task                                        paper_title  \\\n",
       "0  Scene Text Detection  Detecting Oriented Text in Natural Images by L...   \n",
       "\n",
       "                                          paper_path  \\\n",
       "0  /paper/detecting-oriented-text-in-natural-imag...   \n",
       "\n",
       "                                paper_url  \\\n",
       "0  https://arxiv.org/pdf/1703.06520v3.pdf   \n",
       "\n",
       "                                paper_abs  \n",
       "0  https://arxiv.org/abs/1703.06520v3.pdf  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['paper_abs'] = df.paper_url.str.replace('/pdf', '/abs')\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>extradata</th>\n",
       "      <th>global_rank</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>model</th>\n",
       "      <th>remove</th>\n",
       "      <th>task</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_path</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC15</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 10</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Scene Text Detection</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1703.06520v3.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset  extradata global_rank metric_name metric_value    model remove  \\\n",
       "0    IC15        NaN        # 10   F-Measure       75.61%  SegLink      -   \n",
       "\n",
       "                   task                                        paper_title  \\\n",
       "0  Scene Text Detection  Detecting Oriented Text in Natural Images by L...   \n",
       "\n",
       "                                          paper_path  \\\n",
       "0  /paper/detecting-oriented-text-in-natural-imag...   \n",
       "\n",
       "                                paper_url  \\\n",
       "0  https://arxiv.org/pdf/1703.06520v3.pdf   \n",
       "\n",
       "                                paper_abs  \n",
       "0  https://arxiv.org/abs/1703.06520v3.pdf  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100 = df[:10]\n",
    "\n",
    "df_100.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract paper abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1703.06520v3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:33:45,951 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1703.06520v3.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1703-06520v3-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1607.04315v3.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:05,492 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1607.04315v3.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1607-04315v3-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1807.09956v2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:08,756 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1807.09956v2.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1807-09956v2-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1809.11096v2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:11,447 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1809.11096v2.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1809-11096v2-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1811.01136v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:34,642 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1811.01136v1.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1811-01136v1-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1806.02817v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:37,785 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1806.02817v1.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1806-02817v1-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1804.09530v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:44,607 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1804.09530v1.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1804-09530v1-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1809.00219v2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:34:47,792 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1809.00219v2.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1809-00219v2-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1809.08370v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:35:00,584 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1809.08370v1.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1809-08370v1-pdf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://arxiv.org/abs/1804.08460v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-17 22:35:04,367 [MainThread  ] [INFO ]  Retrieving https://arxiv.org/pdf/1804.08460v1.pdf to /var/folders/1x/nph4r0452v1dk6t51bknf9080000gn/T/https-arxiv-org-pdf-1804-08460v1-pdf.\n",
      "/Users/nialdaly/Documents/gpt-2_model/venv/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/nialdaly/Documents/gpt-2_model/venv/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "abstract_text = []\n",
    "\n",
    "paper_text = []\n",
    "\n",
    "for index, row in df_100.iterrows():\n",
    "    \n",
    "    print(row['paper_abs'])\n",
    "    \n",
    "    # adds abstract text to list\n",
    "    abs_url = row['paper_abs']\n",
    "    html_doc = requests.get(abs_url).content\n",
    "    soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "    abstract = soup.find('blockquote', attrs={'class':'abstract mathjax'})\n",
    "    abstract_text.append(abstract.text)\n",
    "    \n",
    "    # adds paper text to list\n",
    "    content = parser.from_file(row['paper_url'])\n",
    "#     text = content['content']\n",
    "    text = re.sub(r'\\[[0-9]*\\]', ' ', str(content['content']))  \n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    paper_text.append(text)\n",
    "    \n",
    "df_100['abstract'] = abstract_text\n",
    "df_100['paper_text'] = paper_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>extradata</th>\n",
       "      <th>global_rank</th>\n",
       "      <th>metric_name</th>\n",
       "      <th>metric_value</th>\n",
       "      <th>model</th>\n",
       "      <th>remove</th>\n",
       "      <th>task</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_path</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_abs</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IC15</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 10</td>\n",
       "      <td>F-Measure</td>\n",
       "      <td>75.61%</td>\n",
       "      <td>SegLink</td>\n",
       "      <td>-</td>\n",
       "      <td>Scene Text Detection</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>/paper/detecting-oriented-text-in-natural-imag...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1703.06520v3.pdf</td>\n",
       "      <td>Abstract:  Most state-of-the-art text detectio...</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNLI</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 36</td>\n",
       "      <td>% Test Accuracy</td>\n",
       "      <td>84.6</td>\n",
       "      <td>300D NSE encoders</td>\n",
       "      <td>-</td>\n",
       "      <td>Natural Language Inference</td>\n",
       "      <td>Neural Semantic Encoders</td>\n",
       "      <td>/paper/neural-semantic-encoders</td>\n",
       "      <td>https://arxiv.org/pdf/1607.04315v3.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1607.04315v3.pdf</td>\n",
       "      <td>Abstract:  We present a memory augmented neura...</td>\n",
       "      <td>Neural Semantic Encoders Tsendsuren Munkhdala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VQA v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 2</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>70.24%</td>\n",
       "      <td>Pythia v0.1</td>\n",
       "      <td>-</td>\n",
       "      <td>Visual Question Answering</td>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Chal...</td>\n",
       "      <td>/paper/pythia-v01-the-winning-entry-to-the-vqa</td>\n",
       "      <td>https://arxiv.org/pdf/1807.09956v2.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1807.09956v2.pdf</td>\n",
       "      <td>Abstract:  This document describes Pythia v0.1...</td>\n",
       "      <td>Pythia v0.1: the Winning Entry to the VQA Cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ImageNet 128x128</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 3</td>\n",
       "      <td>FID</td>\n",
       "      <td>9.6</td>\n",
       "      <td>BigGAN</td>\n",
       "      <td>-</td>\n",
       "      <td>Conditional Image Generation</td>\n",
       "      <td>Large Scale GAN Training for High Fidelity Nat...</td>\n",
       "      <td>/paper/large-scale-gan-training-for-high-fidelity</td>\n",
       "      <td>https://arxiv.org/pdf/1809.11096v2.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1809.11096v2.pdf</td>\n",
       "      <td>Abstract:  Despite recent progress in generati...</td>\n",
       "      <td>Published as a conference paper at ICLR 2019 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BUCC French-to-English</td>\n",
       "      <td>NaN</td>\n",
       "      <td># 2</td>\n",
       "      <td>F1 score</td>\n",
       "      <td>92.89</td>\n",
       "      <td>Multilingual Sentence Embeddings</td>\n",
       "      <td>-</td>\n",
       "      <td>Cross-Lingual Bitext Mining</td>\n",
       "      <td>Margin-based Parallel Corpus Mining with Multi...</td>\n",
       "      <td>/paper/margin-based-parallel-corpus-mining-with</td>\n",
       "      <td>https://arxiv.org/pdf/1811.01136v1.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1811.01136v1.pdf</td>\n",
       "      <td>Abstract:  Machine translation is highly sensi...</td>\n",
       "      <td>Margin-based Parallel Corpus Mining with Mult...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset  extradata global_rank      metric_name  \\\n",
       "0                     IC15        NaN        # 10        F-Measure   \n",
       "2                     SNLI        NaN        # 36  % Test Accuracy   \n",
       "12                  VQA v2        NaN         # 2         Accuracy   \n",
       "13        ImageNet 128x128        NaN         # 3              FID   \n",
       "17  BUCC French-to-English        NaN         # 2         F1 score   \n",
       "\n",
       "   metric_value                             model remove  \\\n",
       "0        75.61%                           SegLink      -   \n",
       "2          84.6                 300D NSE encoders      -   \n",
       "12       70.24%                       Pythia v0.1      -   \n",
       "13          9.6                            BigGAN      -   \n",
       "17        92.89  Multilingual Sentence Embeddings      -   \n",
       "\n",
       "                            task  \\\n",
       "0           Scene Text Detection   \n",
       "2     Natural Language Inference   \n",
       "12     Visual Question Answering   \n",
       "13  Conditional Image Generation   \n",
       "17   Cross-Lingual Bitext Mining   \n",
       "\n",
       "                                          paper_title  \\\n",
       "0   Detecting Oriented Text in Natural Images by L...   \n",
       "2                            Neural Semantic Encoders   \n",
       "12  Pythia v0.1: the Winning Entry to the VQA Chal...   \n",
       "13  Large Scale GAN Training for High Fidelity Nat...   \n",
       "17  Margin-based Parallel Corpus Mining with Multi...   \n",
       "\n",
       "                                           paper_path  \\\n",
       "0   /paper/detecting-oriented-text-in-natural-imag...   \n",
       "2                     /paper/neural-semantic-encoders   \n",
       "12     /paper/pythia-v01-the-winning-entry-to-the-vqa   \n",
       "13  /paper/large-scale-gan-training-for-high-fidelity   \n",
       "17    /paper/margin-based-parallel-corpus-mining-with   \n",
       "\n",
       "                                 paper_url  \\\n",
       "0   https://arxiv.org/pdf/1703.06520v3.pdf   \n",
       "2   https://arxiv.org/pdf/1607.04315v3.pdf   \n",
       "12  https://arxiv.org/pdf/1807.09956v2.pdf   \n",
       "13  https://arxiv.org/pdf/1809.11096v2.pdf   \n",
       "17  https://arxiv.org/pdf/1811.01136v1.pdf   \n",
       "\n",
       "                                 paper_abs  \\\n",
       "0   https://arxiv.org/abs/1703.06520v3.pdf   \n",
       "2   https://arxiv.org/abs/1607.04315v3.pdf   \n",
       "12  https://arxiv.org/abs/1807.09956v2.pdf   \n",
       "13  https://arxiv.org/abs/1809.11096v2.pdf   \n",
       "17  https://arxiv.org/abs/1811.01136v1.pdf   \n",
       "\n",
       "                                             abstract  \\\n",
       "0   Abstract:  Most state-of-the-art text detectio...   \n",
       "2   Abstract:  We present a memory augmented neura...   \n",
       "12  Abstract:  This document describes Pythia v0.1...   \n",
       "13  Abstract:  Despite recent progress in generati...   \n",
       "17  Abstract:  Machine translation is highly sensi...   \n",
       "\n",
       "                                           paper_text  \n",
       "0    Detecting Oriented Text in Natural Images by ...  \n",
       "2    Neural Semantic Encoders Tsendsuren Munkhdala...  \n",
       "12   Pythia v0.1: the Winning Entry to the VQA Cha...  \n",
       "13   Published as a conference paper at ICLR 2019 ...  \n",
       "17   Margin-based Parallel Corpus Mining with Mult...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Remove unneccessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_abs</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Detecting Oriented Text in Natural Images by L...</td>\n",
       "      <td>https://arxiv.org/pdf/1703.06520v3.pdf</td>\n",
       "      <td>https://arxiv.org/abs/1703.06520v3.pdf</td>\n",
       "      <td>Abstract:  Most state-of-the-art text detectio...</td>\n",
       "      <td>Detecting Oriented Text in Natural Images by ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         paper_title  \\\n",
       "0  Detecting Oriented Text in Natural Images by L...   \n",
       "\n",
       "                                paper_url  \\\n",
       "0  https://arxiv.org/pdf/1703.06520v3.pdf   \n",
       "\n",
       "                                paper_abs  \\\n",
       "0  https://arxiv.org/abs/1703.06520v3.pdf   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract:  Most state-of-the-art text detectio...   \n",
       "\n",
       "                                          paper_text  \n",
       "0   Detecting Oriented Text in Natural Images by ...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_100 = df_100[['paper_title', 'paper_url', 'paper_abs', 'abstract', 'paper_text']]\n",
    "\n",
    "df_100.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_100.to_csv('../data/gpt-2_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# abs_text = [s.strip('Abstract:  ') for s in abs_text]\n",
    "\n",
    "# abs_text = ' '.join(abs_text)\n",
    "\n",
    "# # removes square brackets and extra spaces\n",
    "# abs_text = re.sub(r'\\s+', ' ', abs_text)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-2-model",
   "language": "python",
   "name": "gpt-2-model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
